% 此文件针对问题1 2，用于预测是否违约
filename = 'C:\\Users\\DELL\\Desktop\\2018年数模校内赛题目\\2018年数模校内赛题目\\问题B：不完全对称信息下的客户授信评估问题\\creditdata.xlsx';
sheet = 1;
xlRange='C2:AF284808'; %AF后还应加上行数 训练数据共有284726个
data = xlsread(filename, sheet, xlRange);
pca_data = data(:,1:29); % 这个数据用于进行pca，其中test数据()同样被pca，这样方便预测

classify_label=data(1:284727,30); %0 1 需要变成 1 -1 test_data是从284728-284807
pos=classify_label==0;
classify_label(pos)=-1;% 将0变为-1
%regress_label = train_label(1); %amount

% 下面对数据进行保存，这样下一次读取就直接从mat格式数据读取了
%save pca_data.mat train_data
%save classify_label.mat classify_label
%save regress_label.mat regress_label
%save test_data.mat test_data

% 若已经保存，则直接读取
%train_data=load('train_data.mat');
%classify_label=load('classify_label.mat');
%regress_label=load('regress_label.mat');
%test_data=load('test_data.mat');

stdr = std(pca_data); % 得到标准差
[n, m] = size(pca_data); % 矩阵的行与列
sddata=pca_data./stdr(ones(n, 1), :); %标准化
[p,princ,egenvalue]=princomp(sddata);  %调用主成分
% p是一个m*m方阵，-0每一列包含一个主成份的系数
% princ是对主成分的打分，n*m
%p=p(:,1:3);                            %输出前3主成分系数；
%sc=princ(:,1:3);                       %前3主成分量，后面在做SVM的时候就直接用这个作为输入的特征
egenvalue;                              %相关系数矩阵的特征值，即各主成分所占比例；
per=100*egenvalue/sum(egenvalue);       %各个主成分所占百分比；

% 接下来对数据进行一个直观的了解
% 先读取各列，即各类数值的含义,读取的时候遇到了问题，暂时用1-28数字来代替每个原始特征
% V_name = 'd:\\math\\V1-V28.xlsx';
% V1_V28 = xlsread(V_name, 1); % 只包含了V1-V28的名称
V1_V29=1:29;
bar(V1_V29, per); % 显示柱状图，柱状图的x坐标是1到28，值是每个原始特征的主成份占比

% 挑选和为前85%  前24个 的主成进行分析，输入到SVM中
[after, index_before]=sort(per);
% after就是进行过升序排序的per，而index_before就是排序后的每个元素的在原来的向量中的下标
% after中的每个元素不超过1，和为1
sum = 0;
index=[];
for i=fliplr(V1_V28), % 从后往前累加，找到刚好大于0.85的那个下标
    sum = sum+after(i);
    if sum>=85,
        index=i:28;
        break;
    end
end

top=index_before(index); % top是一个向量，包含了和为前85%占比的主成份的下标,用这个作为princ的索引即可得到和为前85%的主成份

princ = princ(:,top); % 得到和为85%以上的主成分
disp(size(princ)); % 显示行数与列数，即样本数与主成成分数

test_data=princ(284728:284807,:);
train_data=princ(1:284727,:);
% 训练SVM,train_label中的标注为1或者-1才行
% 不适用了SVMStruct=svmtrain(train_data(:,1:24),classify_label,'kernel_function', 'rbf','rbf_sigma',1,'Showplot',true);      % train  


SVMModel = fitcsvm(train_data,classify_label,'Standardize',true,'KernelFunction','RBF',...
    'KernelScale','auto');
% 进行预测是否可以贷款给这个人，Group中为1表示违约客户，-1表示正常客户
[class, score]=predict(SVMModel,test_data);
% 其中class(i)是第i个测试样本分的类别 score(i,1)是概率，当score大于零的时候class为-1（正常客户），score小于零的时候class为1（违约客户）
% 接下来验证模型
CVSVMOdel=crossval(SVMModel);
classLoss=kfoldLoss(CVSMModel);
%classLoss=0.000544381108921811;
% 表示我们在验证集上的准确率已经达到了99.9%以上 

save 'classify_model.mat' SVMModel;% 保存训练好的SVM模型

% 可以使用如下语句读取
model = cell2mat(struct2cell(load('classify_model.mat')));
% 保存到excel中
p=class==-1;
class(p)=0;
xlswrite('predict.xlsx', class);

% 下面是80个测试样本的score（两列，第一列符合之前的说的）
%{
-1.22228603486598          1.22228603486598
          1.01140493067363         -1.01140493067363
          1.00796687784977         -1.00796687784977
          1.04193325772788         -1.04193325772788
          1.04725280118741         -1.04725280118741
         -1.11670035072028          1.11670035072028
         0.168497341024424        -0.168497341024424
          1.01274870361867         -1.01274870361867
        -0.864746965015913         0.864746965015913
         -1.07548536984503          1.07548536984503
          1.03197757960604         -1.03197757960604
        -0.906931223841372         0.906931223841372
          1.05527325669613         -1.05527325669613
          1.06993217080259         -1.06993217080259
        -0.635379685146309         0.635379685146309
         -0.84401914149971          0.84401914149971
        -0.889982472762632         0.889982472762632
          1.02611327908606         -1.02611327908606
          1.03396331820283         -1.03396331820283
         -1.48138646768575          1.48138646768575
         -1.18536405789993          1.18536405789993
          1.02088598340536         -1.02088598340536
        -0.574435173538963         0.574435173538963
         -1.21506672527004          1.21506672527004
          1.03543378885494         -1.03543378885494
          1.05331731625545         -1.05331731625545
          1.05928517765679         -1.05928517765679
          1.03724675053545         -1.03724675053545
          1.01434442174704         -1.01434442174704
          1.01070356053796         -1.01070356053796
          1.03637335847727         -1.03637335847727
          1.08233644046973         -1.08233644046973
         -1.46370967235969          1.46370967235969
          1.02177808591581         -1.02177808591581
          1.01072864062533         -1.01072864062533
          -1.1148496270444           1.1148496270444
          1.04026558312442         -1.04026558312442
          1.03858080381884         -1.03858080381884
          1.03704026787135         -1.03704026787135
         0.973875532428155        -0.973875532428155
         -1.02804337426484          1.02804337426484
          1.04324124986784         -1.04324124986784
          1.02525417219253         -1.02525417219253
          1.03980507880805         -1.03980507880805
          1.03715539226205         -1.03715539226205
          1.01419876678185         -1.01419876678185
         0.201491135650989        -0.201491135650989
          1.06988251824982         -1.06988251824982
          1.03218948562623         -1.03218948562623
          1.03138111760644         -1.03138111760644
          1.04074023169893         -1.04074023169893
          1.02074624801693         -1.02074624801693
          1.02713041578048         -1.02713041578048
        -0.853550418127702         0.853550418127702
           1.0346272088737          -1.0346272088737
          1.03827026732734         -1.03827026732734
          1.03267748278787         -1.03267748278787
          1.01974487257489         -1.01974487257489
          1.21075799344881         -1.21075799344881
          1.03452142685026         -1.03452142685026
          1.00981964413157         -1.00981964413157
         -1.09930520100906          1.09930520100906
        -0.842761751922143         0.842761751922143
           1.0529641634653          -1.0529641634653
           1.0553304815633          -1.0553304815633
          1.03069820316293         -1.03069820316293
            1.029662934232           -1.029662934232
         -1.19596985363791          1.19596985363791
          1.01162863466227         -1.01162863466227
         -1.05773584899231          1.05773584899231
          1.05904529866657         -1.05904529866657
        -0.674163644233268         0.674163644233268
          1.01317418818714         -1.01317418818714
           1.0303156080607          -1.0303156080607
          1.02188206242559         -1.02188206242559
           0.9938022394955          -0.9938022394955
          1.10400196301279         -1.10400196301279
          1.05191122410613         -1.05191122410613
         -1.24848119585225          1.24848119585225
          1.01049556298772         -1.01049556298772%}
% 80个label为
{%
     1
    -1
    -1
    -1
    -1
     1
    -1
    -1
     1
     1
    -1
     1
    -1
    -1
     1
     1
     1
    -1
    -1
     1
     1
    -1
     1
     1
    -1
    -1
    -1
    -1
    -1
    -1
    -1
    -1
     1
    -1
    -1
     1
    -1
    -1
    -1
    -1
     1
    -1
    -1
    -1
    -1
    -1
    -1
    -1
    -1
    -1
    -1
    -1
    -1
     1
    -1
    -1
    -1
    -1
    -1
    -1
    -1
     1
     1
    -1
    -1
    -1
    -1
     1
    -1
     1
    -1
     1
    -1
    -1
    -1
    -1
    -1
    -1
     1
    -1%}